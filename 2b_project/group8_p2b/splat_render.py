import numpy as np
import torch
import cv2
import json

from pathlib import Path
from dataclasses import fields
from transforms3d.euler import euler2mat

from torch.serialization import add_safe_globals

from nerfstudio.configs.base_config import ViewerConfig
from nerfstudio.engine.trainer import TrainerConfig
from nerfstudio.pipelines.base_pipeline import Pipeline
from nerfstudio.utils.eval_utils import eval_setup
from nerfstudio.utils.colormaps import ColormapOptions, apply_colormap
from nerfstudio.viewer.utils import CameraState, get_camera
from nerfstudio.cameras.cameras import CameraType

import math
import numpy as np

def quaternion_to_euler(x_rot, y_rot, z_rot, w):
    """Convert quaternion to roll, pitch, yaw (Euler angles)"""
    t0 = +2.0 * (w * x_rot + y_rot * z_rot)
    t1 = +1.0 - 2.0 * (x_rot * x_rot + y_rot * y_rot)
    roll = math.atan2(t0, t1)
    
    t2 = +2.0 * (w * y_rot - z_rot * x_rot)
    t2 = max(min(t2, 1.0), -1.0)
    pitch = math.asin(t2)

    t3 = +2.0 * (w * z_rot + x_rot * y_rot)
    t4 = +1.0 - 2.0 * (y_rot * y_rot + z_rot * z_rot)
    yaw = math.atan2(t3, t4)

    return roll, pitch, yaw

def euler_to_quaternion(roll, pitch, yaw):
    """
    Converts Euler Angles to Quaternion
    """
    qx = np.sin(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) - np.cos(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)
    qy = np.cos(roll/2) * np.sin(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.cos(pitch/2) * np.sin(yaw/2)
    qz = np.cos(roll/2) * np.cos(pitch/2) * np.sin(yaw/2) - np.sin(roll/2) * np.sin(pitch/2) * np.cos(yaw/2)
    qw = np.cos(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)

    return [qw, qx, qy, qz]

def quaternion_multiply(quaternion1, quaternion0):
    """
    Multiplies 2 quaternions
    """
    w0, x0, y0, z0 = quaternion0
    w1, x1, y1, z1 = quaternion1
    return np.array([-x1 * x0 - y1 * y0 - z1 * z0 + w1 * w0,
                    x1 * w0 + y1 * z0 - z1 * y0 + w1 * x0,
                    -x1 * z0 + y1 * w0 + z1 * x0 + w1 * y0,
                    x1 * y0 - y1 * x0 + z1 * w0 + w1 * z0], dtype=np.float64)


def rotation_matrix_from_euler(roll, pitch, yaw):
    """
    make rotation matrix from rol, pitch, yaw
    """
    cr = np.cos(roll)
    sr = np.sin(roll)
    cp = np.cos(pitch)
    sp = np.sin(pitch)
    cy = np.cos(yaw)
    sy = np.sin(yaw)
    R = np.array([
        [cy * cp, cy * sp * sr - sy * cr, cy * sp * cr + sy * sr],
        [sy * cp, sy * sp * sr + cy * cr, sy * sp * cr - cy * sr],
        [-sp, cp * sr, cp * cr]
    ])
    return R



class SplatRenderer:
    def __init__(self, config_path: str, json_path: str, aspect_ratio: float = 4/3):
# splat_render.py


        add_safe_globals([np.core.multiarray.scalar])  # allowlist NumPy scalar from old checkpoints

        config, pipeline, _, _ = eval_setup(Path(config_path), eval_num_rays_per_chunk=None, test_mode="test")

        config, pipeline, _, _ = eval_setup(Path(config_path), eval_num_rays_per_chunk=None, test_mode="test")
        self.config = config
        self.pipeline = pipeline
        self.model = pipeline.model
        self.model.eval()
        self.device = self.model.device
        self.aspect_ratio = aspect_ratio

        # Set background
        self.background_color = torch.tensor([0.1490, 0.1647, 0.2157], device=self.device)
        self.model.set_background(self.background_color)

        # Load camera settings
        with open(json_path, 'r') as f:
            camera_data = json.load(f)
        cam_matrix = np.array(camera_data["camera"]["c2w_matrix"])
        self.init_position = cam_matrix[:, 3]
        self.init_orientation = cam_matrix[:, :3]

        fov = camera_data["camera"].get("fov_radians", 1.3089969389957472)
        resolution = camera_data["camera"].get("render_resolution", 1080)
        self.fov = fov
        self.image_height = resolution
        self.image_width = int(resolution * aspect_ratio)

        self.colormap_options_rgb = ColormapOptions(colormap='default', normalize=True)
        self.colormap_options_depth = ColormapOptions(colormap='gray', normalize=True)

    def render(self, position: np.ndarray, orientation_rpy: np.ndarray):
        """
        position: (3,) [x, y, z] in meters (in NED frame)
        orientation_rpy: (3,) [roll, pitch, yaw] in radians (in NED frame)
        Returns: RGB and Depth images (uint8)
        """
        # Position transform from NED â†’ GSplat (NWU)
        pos_update = self.init_orientation @ np.array([
            [position[1]],  # East
            [-position[2]], # Up
            [-position[0]]  # Forward
        ])
        pos_cam = self.init_position + pos_update.flatten()

        # Orientation (NED to GSplat)
        R_ned = euler2mat(orientation_rpy[0], orientation_rpy[1], orientation_rpy[2])
        R_cam = self.init_orientation @ euler2mat(
            orientation_rpy[1], -orientation_rpy[2], -orientation_rpy[0]
        )
        # print('R NED ', R_ned)
        # print("R Camera ", R_cam)
        c2w = torch.tensor(np.column_stack([R_cam, pos_cam]), dtype=torch.float32, device=self.device)
        # print('Camera to World Transform ', c2w)
        camera_state = CameraState(
            fov=self.fov,
            aspect=self.aspect_ratio,
            c2w=c2w,
            camera_type=CameraType.PERSPECTIVE
        )
        # print('Camera State ', camera_state)

        camera = get_camera(camera_state, self.image_height, self.image_width).to(self.device)
        outputs = self.model.get_outputs_for_camera(camera)

        # print('outputs ', outputs["rgb"].dtype)

        rgb = apply_colormap(outputs["rgb"], self.colormap_options_rgb)
        rgb = (rgb * 255).type(torch.uint8).cpu().numpy()
        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)

        depth = apply_colormap(outputs["depth"], self.colormap_options_depth)
        depth = (depth * 255).type(torch.uint8).cpu().numpy()

        return rgb, depth
